{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "880ed483-5df3-407b-819f-57d06cfcae66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: Create a .env file and put gemini keys in there as `GEMINI_API_KEY=...`\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f074a330-d6fd-4653-a41d-10146f959155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "data_dir = f'{parent_dir}/data'\n",
    "results_dir = f'{parent_dir}/gemini_output/markdown_pubmed'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ai_PykEiyj_X",
   "metadata": {
    "id": "Ai_PykEiyj_X"
   },
   "source": [
    "## Download data from PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T6OAqkDrykXg",
   "metadata": {
    "id": "T6OAqkDrykXg"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from time import sleep\n",
    "\n",
    "from Bio import Entrez, Medline\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set your email and API key\n",
    "Entrez.email = \"your_email@example.com\"\n",
    "api_key = os.environ['PUBMED_API_KEY']\n",
    "\n",
    "# Search for the latest articles in below categories\n",
    "search_term = \"biology OR medicine OR healthcare\"\n",
    "articles = []\n",
    "\n",
    "# Number of years to retrieve and batch size for each request\n",
    "num_years = 5\n",
    "max_size = 9999\n",
    "\n",
    "for i in tqdm(range(num_years)):\n",
    "    year = 2024 - i\n",
    "    handle1 = Entrez.esearch(\n",
    "        db=\"pubmed\",\n",
    "        sort=\"relevance\",\n",
    "        mindate=year,\n",
    "        maxdate=year,\n",
    "        term=search_term,\n",
    "        retmax=max_size,\n",
    "        api_key=api_key\n",
    "    )\n",
    "    record = Entrez.read(handle1)\n",
    "    handle1.close()\n",
    "\n",
    "    # Fetch details for the articles\n",
    "    id_list = record[\"IdList\"]\n",
    "    handle2 = Entrez.efetch(db=\"pubmed\", id=id_list, rettype=\"medline\", retmode=\"text\", api_key=api_key)\n",
    "    records = Medline.parse(handle2)\n",
    "\n",
    "    for index, record in enumerate(records):\n",
    "        title = record.get('TI', None)\n",
    "        abstract = record.get('AB', None)\n",
    "        if title and abstract:\n",
    "            num_words = len(abstract.split())\n",
    "            articles.append([title, abstract, num_words])\n",
    "\n",
    "    handle2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ztTrsyL-1zNK",
   "metadata": {
    "id": "ztTrsyL-1zNK"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['title', 'abstract', '#words'], data=articles)\n",
    "df.drop_duplicates(inplace=True) # Some articles have both their peer reviewed and preprint versions listed\n",
    "df.to_csv(f'{data_dir}/PubMed_articles.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c02ec4-e6b2-4cae-8112-40b65ce544a3",
   "metadata": {},
   "source": [
    "### Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc9c7995-3c76-41bd-858b-36b34ce0ae80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>40891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>222.882223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>86.550538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>163.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>227.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1148.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             #words\n",
       "count  40891.000000\n",
       "mean     222.882223\n",
       "std       86.550538\n",
       "min        1.000000\n",
       "25%      163.000000\n",
       "50%      227.000000\n",
       "75%      272.000000\n",
       "max     1148.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "DosEQGqv4ZbR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DosEQGqv4ZbR",
    "outputId": "35d048fc-1ed1-4c63-acff-32601547fa85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['N-of-1 medicine.',\n",
       " \"The fields of precision and personalised medicine have led to promising advances in tailoring treatment to individual patients. Examples include genome/molecular alteration-guided drug selection, single-patient gene therapy design and synergy-based drug combination development, and these approaches can yield substantially diverse recommendations. Therefore, it is important to define each domain and delineate their commonalities and differences in an effort to develop novel clinical trial designs, streamline workflow development, rethink regulatory considerations, create value in healthcare and economics assessments, and other factors. These and other segments are essential to recognise the diversity within these domains to accelerate their respective workflows towards practice-changing healthcare. To emphasise these points, this article elaborates on the concept of digital health and digital medicine-enabled N-of-1 medicine, which individualises combination regimen and dosing using a patient's own data. We will conclude with recommendations for consideration when developing novel workflows based on emerging digital-based platforms.\",\n",
       " 146]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Op3KMboHKHjZ",
   "metadata": {
    "id": "Op3KMboHKHjZ"
   },
   "source": [
    "### Clean abstracts\n",
    "* Some abstracts may contain HTML tags wheras others may contain URL links.\n",
    "* We decided to retain the URL links but remove the HTML tags.\n",
    "* Section headings such as `AIM`, `OBSERVATION`, `CONCLUSION`, etc present in the PubMed abstracts are removed as most model tend to summarise and thus section headings are not needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "FL_B25kvLijz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FL_B25kvLijz",
    "outputId": "c92cbca9-d389-4bc1-a86f-744eb9f1ca5e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_37163/2479256924.py:15: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(strings[i], \"html.parser\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of abstracts with HTML tags: 25\n",
      "Number of abstracts with URLs: 655\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "\n",
    "def clean_html(strings: List[str]) -> List[str]:\n",
    "    count_html = 0\n",
    "    count_url = 0\n",
    "    \n",
    "    url_regex = r\"(https?://[^\\s]+)\"\n",
    "    # We remove special patterns which can be misidentified as HTML tags\n",
    "    patterns_to_exclude = [r'<<.*?>>']\n",
    "\n",
    "    for i in range(len(strings)):\n",
    "        for pattern in patterns_to_exclude:\n",
    "            strings[i] = re.sub(pattern, '', strings[i])\n",
    "        soup = BeautifulSoup(strings[i], \"html.parser\")\n",
    "        if soup.find():\n",
    "            strings[i] = soup.get_text()\n",
    "            count_html += 1\n",
    "        if bool(re.search(url_regex, strings[i])):\n",
    "            count_url += 1\n",
    "    \n",
    "    print(f\"Number of abstracts with HTML tags: {count_html}\")\n",
    "    print(f\"Number of abstracts with URLs: {count_url}\")\n",
    "    \n",
    "    return strings\n",
    "\n",
    "df['abstract'] = clean_html(df['abstract'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DgE6wSC8L7xu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DgE6wSC8L7xu",
    "outputId": "273e2402-b052-4fed-e042-32d0b5540692"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# Sections headings were observed to be in CAPS followed by colon and whitespace.\n",
    "regex = r\"[A-Z]{4,}:\\s+\"\n",
    "\n",
    "matches = []\n",
    "for abstract in abstracts:\n",
    "    matches.extend(re.findall(regex, abstract))\n",
    "\n",
    "# Count the frequency of each match and display in descending order\n",
    "counts = Counter(matches)\n",
    "counts = counts.most_common()\n",
    "\n",
    "# Print the frequency of each match\n",
    "sections_to_remove = list()\n",
    "for match, count in counts:\n",
    "    if count < 10:\n",
    "        break\n",
    "    sections_to_remove.append(match)\n",
    "    print(f\"{match}: {count}\")\n",
    "\n",
    "# Removing these sections\n",
    "section_regex = '|'.join(re.escape(section) for section in sections_to_remove)\n",
    "df['abstract'] = [re.sub(section_regex, '', abstract) for abstract in df['abstract'].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NT6bzxqHJ9Mp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NT6bzxqHJ9Mp",
    "outputId": "867bde15-9052-46a0-c4e3-357b5757a1c5"
   },
   "outputs": [],
   "source": [
    "# Save the downloaded and cleaned data\n",
    "df.to_csv(f'{data_dir}/PubMed_articles_cleaned.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a97b9d5-9fd8-48d1-a650-dc6142c2a801",
   "metadata": {
    "id": "5a97b9d5-9fd8-48d1-a650-dc6142c2a801"
   },
   "source": [
    "## Using Google Gemini API\n",
    "\n",
    "See the getting started guide for more information:\n",
    "https://ai.google.dev/gemini-api/docs/get-started/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bee02ca5-348b-445e-bcae-b846e73ed830",
   "metadata": {
    "id": "bee02ca5-348b-445e-bcae-b846e73ed830"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import google.generativeai as genai\n",
    "from google.api_core.retry import Retry\n",
    "\n",
    "genai.configure(api_key=os.environ['GEMINI_API_KEY'])\n",
    "\n",
    "# Create the model\n",
    "# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel\n",
    "generation_config = {\n",
    "  \"temperature\": 1,\n",
    "  \"top_p\": 0.95,\n",
    "  \"top_k\": 64,\n",
    "  \"max_output_tokens\": 8192,\n",
    "  \"response_mime_type\": \"text/plain\",\n",
    "}\n",
    "# Safety settings are disabled as input text describing\n",
    "# patient's mental health experience can contain disturbing\n",
    "# content which is blocked by Gemini API filters.\n",
    "safety_settings = [\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "    \"threshold\": \"BLOCK_LOW_AND_ABOVE\",\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "    \"threshold\": \"BLOCK_LOW_AND_ABOVE\",\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "    \"threshold\": \"BLOCK_LOW_AND_ABOVE\",\n",
    "  },\n",
    "  {\n",
    "    \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "    \"threshold\": \"BLOCK_LOW_AND_ABOVE\",\n",
    "  },\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-flash\",\n",
    "    safety_settings=safety_settings,\n",
    "    generation_config=generation_config,\n",
    ")\n",
    "\n",
    "def generate(description: str) -> str:\n",
    "    '''\n",
    "    Generate output using Gemini-Flash API.\n",
    "    Response is in markdown format.\n",
    "    '''\n",
    "    intro = \"The below text contains some biomedical literature which is difficult for a layperson to understand.\"\n",
    "    # Below instructions are used by the model to convert the description into a structured format\n",
    "    instructions = \"For the above text, create a simplified English version of the text which can be understood by a native English layperson with no medical background. Put the section heading as English simplified. The output section should have 1 paragraphs corresponding to the input text.\\nNext, create an even more simpler version of the text which can be understood by a native English school kid with no medical background. Put the section heading as English super simplified. The output section should have 1 paragraphs corresponding to the input text.\\n\\nNext, created translated version of the simplified text in the following languages: Mandarin, followed by Spanish, followed by Arabic, followed by Hindi, followed by Bengali, followed by Portuguese, followed by Russian, followed by Japanese, followed by Punjabi\\nPut the section heading as Langauge name Simplified. The output section should have 1 paragraphs corresponding to the input text. If some English terms excluding acronyms and numbers can't be translated then transliterate them.\\n\\nLet the voice in simplified text be same as in the original text so that the person narrating appears consistent. If there any URL links present in the original text then retain them in the simplified text as well.\"\n",
    "\n",
    "    response = model.generate_content(f\"{instructions}\\n\\n{description}\", request_options={'timeout': 150, 'retry': Retry()})\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0301be02-0076-4af1-822c-e907f30ed317",
   "metadata": {
    "id": "0301be02-0076-4af1-822c-e907f30ed317"
   },
   "source": [
    "### Test sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c587b5-b8d8-4984-9ecb-a12bfe51b7ae",
   "metadata": {
    "id": "24c587b5-b8d8-4984-9ecb-a12bfe51b7ae"
   },
   "source": [
    "#### Pubmed abstract sample abstract\n",
    "\n",
    "A 68-year-old man was admitted with hematochezia. Emergency computed tomography showed multiple diverticula throughout the colon. Initial colonoscopy on day 2 showed no active bleeding, but massive hematochezia on day 3 led to the performance of an emergency endoscopy. Substantial bleeding in the ileocecal area obscured the visual field, making it challenging to view the area around the bleeding site. Two endoscopic band ligations (EBLs) were applied at the suspected bleeding sites. Hemostasis was achieved without active bleeding after EBL. However, the patient developed lower right abdominal pain and fever (39.4 degrees C) on day 6. Urgent computed tomography revealed appendiceal inflammation, necessitating emergency open ileocecal resection for acute appendicitis. Pathological examination confirmed acute phlegmonous appendicitis, with EBLs noted at the appendiceal orifice and on the anal side. This case illustrates the efficacy of EBL in managing colonic diverticular bleeding. However, it also highlights the risk of appendicitis due to EBL in cases of ileocecal hemorrhage exacerbated by poor visibility due to substantial bleeding. Endoscopists need to consider this rare but important complication when performing EBL in similar situations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a614c4-2c56-4b12-a238-0e0192fbcea3",
   "metadata": {
    "id": "24a614c4-2c56-4b12-a238-0e0192fbcea3"
   },
   "outputs": [],
   "source": [
    "sample = \"A 68-year-old man was admitted with hematochezia. Emergency computed tomography showed multiple diverticula throughout the colon. Initial colonoscopy on day 2 showed no active bleeding, but massive hematochezia on day 3 led to the performance of an emergency endoscopy. Substantial bleeding in the ileocecal area obscured the visual field, making it challenging to view the area around the bleeding site. Two endoscopic band ligations (EBLs) were applied at the suspected bleeding sites. Hemostasis was achieved without active bleeding after EBL. However, the patient developed lower right abdominal pain and fever (39.4 degrees C) on day 6. Urgent computed tomography revealed appendiceal inflammation, necessitating emergency open ileocecal resection for acute appendicitis. Pathological examination confirmed acute phlegmonous appendicitis, with EBLs noted at the appendiceal orifice and on the anal side. This case illustrates the efficacy of EBL in managing colonic diverticular bleeding. However, it also highlights the risk of appendicitis due to EBL in cases of ileocecal hemorrhage exacerbated by poor visibility due to substantial bleeding. Endoscopists need to consider this rare but important complication when performing EBL in similar situations.\"\n",
    "output = generate(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dabfca-e36a-4eba-91b8-c6130f457549",
   "metadata": {
    "id": "12dabfca-e36a-4eba-91b8-c6130f457549"
   },
   "source": [
    "#### Simplified texts generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334f7035-e53f-4e56-aa94-e886a74ac60f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "334f7035-e53f-4e56-aa94-e886a74ac60f",
    "outputId": "841cceac-12b1-4f10-e2d4-36037a5422a0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(output.replace('**\\n', '**<br>')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c82a4f-2ddf-42b1-b29a-8348e1e7b87a",
   "metadata": {
    "id": "b5c82a4f-2ddf-42b1-b29a-8348e1e7b87a"
   },
   "source": [
    "### Loading PubMed dataset\n",
    "\n",
    "* Load previously downloaded data as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "811bcdfd-bf45-436b-b476-455eedeebe2f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "811bcdfd-bf45-436b-b476-455eedeebe2f",
    "outputId": "238afbe4-b1ee-46e1-acce-2e165948a1cf"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f'{data_dir}/PubMed_articles_cleaned.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00424c9-73dd-4bb0-9a42-0d5a104d5cbe",
   "metadata": {
    "id": "f00424c9-73dd-4bb0-9a42-0d5a104d5cbe"
   },
   "source": [
    "### Generate in batches & parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c3fd44d-a43a-4bf7-a52b-e330a86b84f0",
   "metadata": {
    "id": "0c3fd44d-a43a-4bf7-a52b-e330a86b84f0"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import re\n",
    "from time import sleep\n",
    "from typing import List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from google.api_core.exceptions import ResourceExhausted\n",
    "from joblib import Parallel, delayed\n",
    "from requests.exceptions import RequestException\n",
    "from tqdm import tqdm\n",
    "\n",
    "progress_bar = None\n",
    "RETRIES = 200 # Occasionally, the Gemini API can have glitches\n",
    "failures = list() # All failed inputs get stored here\n",
    "SAVE = True\n",
    "DEBUG = True # Displays errors\n",
    "\n",
    "REQUEST_TIMEOUT = 180 # If it takes longer than 3 minutes then timeout\n",
    "GEMINI_API_LIMIT = 1500\n",
    "GEMINI_MAX_OUT = 8196 # Maximum number of tokens that can be returned\n",
    "TOKEN_RETURN_RATIO = 16 # Approximate output tokens returned for input text\n",
    "\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)\n",
    "\n",
    "\n",
    "def get_model(api_key: str) -> genai.GenerativeModel:\n",
    "    '''Returns a model configured with the API key to be used for parallel requests.'''\n",
    "    module_name = 'google.generativeai'\n",
    "    _genai = importlib.import_module(module_name)\n",
    "    _genai.configure(api_key=api_key)\n",
    "    return _genai.GenerativeModel(\n",
    "        model_name=\"gemini-1.5-flash\",\n",
    "        safety_settings=safety_settings,\n",
    "        generation_config=generation_config,\n",
    "    )\n",
    "\n",
    "\n",
    "def save_batch(text: str) -> None:\n",
    "    matches = list(re.finditer(r\"#*\\s*Text ID (\\d+)\", text))\n",
    "    # Split the text based on Text ids\n",
    "    for i in range(len(matches)):\n",
    "        start = matches[i].start()\n",
    "        if i < len(matches) - 1:\n",
    "            end = matches[i + 1].start()\n",
    "        else:\n",
    "            end = len(text)\n",
    "        record_number = int(matches[i].group(1))\n",
    "\n",
    "        with open(f'{results_dir}/{record_number}.md', 'w') as fp:\n",
    "            fp.write(text[start:end].strip())\n",
    "\n",
    "\n",
    "def generate_and_save(batch: List[Tuple[int, str]]) -> None:\n",
    "    '''\n",
    "    Generates and stores simplified text for the\n",
    "    given batch using the Google Gemini Flash API.\n",
    "    Response can be in markdown format or sometimes as plain text.\n",
    "    '''\n",
    "    # Below instructions are used by the model to convert the description into a structured format\n",
    "    intro = f\"{len(batch)} biomedical literature texts are provided below which are difficult for a layperson to understand.\"\n",
    "    # Below instructions are used by the model to convert the description into a structured format\n",
    "    instructions = \"For each of the above texts, create a simplified English version of the text which can be understood by a native English layperson with no medical background. Put the section heading as English simplified. The output section should have 1 paragraphs corresponding to the input text.\\nNext, create an even more simpler version of the text which can be understood by a native English school kid with no medical background. Put the section heading as English super simplified. The output section should have 1 paragraphs corresponding to the input text.\\n\\nNext, created translated version of the simplified text in the following languages: Mandarin, followed by Spanish, followed by Arabic, followed by Hindi, followed by Bengali, followed by Portuguese, followed by Russian, followed by Japanese, followed by Punjabi\\nPut the section heading as Langauge name Simplified. The output section should have 1 paragraphs corresponding to the input text. If some English terms excluding acronyms and numbers can't be translated then transliterate them. Put the heading for each text as ## Text ID X, where X is the id of the text.\\n\\nLet the voice in simplified text be same as in the original text so that the person narrating appears consistent. If there any URL links present in the original text then retain them in the simplified text as well.\"\n",
    "    batch_description = '\\n\\n'.join([f'Text ID {i}: {desc}'.replace('\\n', ' ') for i, desc in batch])\n",
    "    \n",
    "    try:\n",
    "        response = model.generate_content(f\"{intro}\\n\\n{batch_description}\\n\\n{instructions}\", request_options={'timeout': REQUEST_TIMEOUT})\n",
    "\n",
    "        if SAVE:\n",
    "            save_batch(response.text)\n",
    "\n",
    "    except (RequestException, ValueError):\n",
    "        # For very long output the request can timeout\n",
    "        # For output containing unsafe text, ValueError is raised\n",
    "        if DEBUG:\n",
    "            print(f'Skipped the following indices for producing unsafe outputs:', [i for i, desc in batch])\n",
    "\n",
    "    except Exception as e:\n",
    "        global RETRIES\n",
    "        if RETRIES <= 0:\n",
    "            print(f\"Error for batch: {e}\")\n",
    "            failures.append(batch_description)\n",
    "        else:\n",
    "            RETRIES -= 1\n",
    "            if DEBUG:\n",
    "                print('Retries left:', RETRIES, f'| {type(e).__name__}')\n",
    "            sleep(10+RETRIES%10)\n",
    "            return generate_and_save(batch)\n",
    "\n",
    "    progress_bar.update(1)\n",
    "\n",
    "\n",
    "def batch_generate(descriptions: List[str], start_at: int = 0, n_jobs: int = 1) -> None:\n",
    "    '''\n",
    "    Generates and stores simplified medical text in batches and in parallel.\n",
    "    '''\n",
    "    tasks = list()\n",
    "\n",
    "    # Gemini has a max output limit of 8196, based on which we dynamically select the size of every batch.\n",
    "    i = start_at\n",
    "    while i < len(descriptions) and len(tasks)<GEMINI_API_LIMIT:\n",
    "        batch = []\n",
    "        num_words = 0\n",
    "        for j in range(i, len(descriptions)):\n",
    "            num_words += len(descriptions[j].split())\n",
    "            if j > i and num_words * TOKEN_RETURN_RATIO >= GEMINI_MAX_OUT:\n",
    "                break\n",
    "            batch.append((j, descriptions[j]))\n",
    "        tasks.append((batch,))\n",
    "        i += len(batch)\n",
    "\n",
    "    global progress_bar\n",
    "    progress_bar = tqdm(total=len(tasks))\n",
    "\n",
    "    Parallel(n_jobs=n_jobs, prefer='threads')(delayed(generate_and_save)(*task) for task in tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e265bd40-fdec-481f-ab07-cf639a03f6f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model(os.environ[f'GEMINI_API_KEY'])\n",
    "batch_generate(\n",
    "    descriptions = df['abstract'].tolist(), # Get all records\n",
    "    start_at = max([int(n.split('.')[0])+1 for n in os.listdir(results_dir) if '.md' in n], default=0), # Skip if previously mined\n",
    "    n_jobs = 8 # Adjust based on hardware and Gemini API per minute token rate limit\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3de2d8-b2d2-4417-9283-bae3595ebbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
