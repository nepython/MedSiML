{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text simplifcation model\n",
    "**Credits**: This work has been adapted from the example code provided in the `Transformers` library released under the `Apache license`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "## Fine-tuning T5-base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Nt4D7zPHd4yw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "data_dir = f'{parent_dir}/data'\n",
    "results_dir = f'{parent_dir}/results'\n",
    "\n",
    "model_name = \"t5-base\"\n",
    "model_dir = f\"{model_name.replace('/', '-')}-checkpoints\"\n",
    "\n",
    "# Check if model directory exists and is not empty\n",
    "if os.path.exists(model_dir) and any([item.startswith('checkpoint-') for item in os.listdir(model_dir)]):\n",
    "    model_checkpoint = os.path.join(model_dir, os.listdir(model_dir)[-1])\n",
    "else:\n",
    "    model_checkpoint = model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl"
   },
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7QYTpxXIrIl"
   },
   "source": [
    "We will use the [Datasets](https://github.com/huggingface/datasets) library to process our data and use the [Evaluate](https://github.com/huggingface/evaluate) get the metric we need to use for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IreSlFmlIrIm"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_datasets = load_dataset(\"csv\", data_files=f'{data_dir}/data.tsv', delimiter='\\t')\n",
    "\n",
    "all_columns = raw_datasets.column_names['train']\n",
    "required_columns = ['original', 'english simplified']\n",
    "unrequired_columns = [col for col in all_columns if col not in required_columns]\n",
    "original_col = required_columns[0]\n",
    "target_col = required_columns[-1]\n",
    "\n",
    "# Remove unrequired columns\n",
    "raw_datasets['train'] = raw_datasets['train'].remove_columns(unrequired_columns)\n",
    "\n",
    "# Filter out rows where 'english simplified' is None\n",
    "raw_datasets['train'] = raw_datasets['train'].filter(lambda example: example['english simplified'] is not None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzfPtOMoIrIu"
   },
   "source": [
    "The `dataset` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'original': \"Public trust in physicians has declined over the last 50 years. Future physicians will need to mend the patient-physician trust relationship. In conjunction with the American Medical Association's Accelerating Change in Medical Education initiative, the Mayo Clinic Alix School of Medicine implemented the Science of Health Care Delivery (SHCD) curriculum-a 4-year curriculum that emphasizes interdisciplinary training across population-centered care; person-centered care; team-based care; high-value care; leadership; and health policy, economics, and technology-in 2015. In this medical student perspective, the authors highlight how the SHCD curriculum has the potential to address issues that have eroded patient-physician trust. The curriculum reaches this aim through didactic and/or experiential teachings in health equity, cultural humility and competence, shared decision making, patient advocacy, and safety and quality of care. It is the authors' hope that novel medical education programs such as the SHCD curriculum will allow the nation's future physicians to own their role in rebuilding and fostering public trust in physicians and the health care system.\",\n",
       " 'english simplified': 'People are losing trust in doctors. To fix this, future doctors need to learn how to build strong relationships with their patients. A new program called the Science of Health Care Delivery (SHCD) teaches medical students important skills like working with other healthcare professionals, providing care that focuses on the individual patient, delivering high-quality care, and understanding how health care policies and technology impact the system. The authors believe that programs like SHCD will help future doctors build trust with patients and improve the healthcare system.'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "meFMYGPrbkwp"
   },
   "source": [
    "## Dataset train/validation/test split\n",
    "\n",
    "We split the dataset in the below ratio:\n",
    "- Training set: 99%\n",
    "- Validation set: 0.5%\n",
    "- Test set: 0.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPsvfzq-uAKc",
    "outputId": "113d334c-937b-49bd-9e6a-bd628f58cec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['original', 'english simplified'],\n",
      "        num_rows: 63693\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['original', 'english simplified'],\n",
      "        num_rows: 321\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['original', 'english simplified'],\n",
      "        num_rows: 321\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Calculate sizes for train, validation, and test sets\n",
    "total_n = raw_datasets['train'].num_rows\n",
    "split_n = int(0.005 * total_n)\n",
    "\n",
    "# Define indices for train, validation, and test splits\n",
    "train_indices = list(range(total_n - 2 * split_n))\n",
    "validation_indices = list(range(total_n - 2 * split_n, total_n - split_n))\n",
    "test_indices = list(range(total_n - split_n, total_n))\n",
    "\n",
    "# Perform rigid train-validation-test split\n",
    "raw_datasets[\"validation\"] = raw_datasets[\"train\"].select(indices=validation_indices).shuffle(seed=42)\n",
    "raw_datasets[\"test\"] = raw_datasets[\"train\"].select(indices=test_indices).shuffle(seed=42)\n",
    "raw_datasets[\"train\"] = raw_datasets[\"train\"].select(indices=train_indices).shuffle(seed=42)\n",
    "\n",
    "# Display raw_datasets to verify the splits\n",
    "print(raw_datasets)\n",
    "\n",
    "# used later for tokenization\n",
    "max_input_length = 512\n",
    "max_target_length = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYW2j-_l4FwR",
    "outputId": "681449c4-45e1-4d7e-df8f-44a34a74251b"
   },
   "outputs": [],
   "source": [
    "# # keep only a subsample of the datasets\n",
    "# raw_datasets[\"train\"] = raw_datasets[\"train\"].select(range(10))\n",
    "# raw_datasets[\"validation\"] = raw_datasets[\"validation\"].select(range(1))\n",
    "# raw_datasets[\"test\"] = raw_datasets[\"test\"].select(range(1))\n",
    "\n",
    "# raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHUmphG3IrI3"
   },
   "source": [
    "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "i3j8APAoIrI3"
   },
   "outputs": [],
   "source": [
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=5):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "\n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "id": "SZy5tRB_IrI7",
    "outputId": "3181ebf3-bcb9-4f75-c1b8-de6fb89e01b3",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>english simplified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Keck School of Medicine of USC\\nTeaching hospitals in California\\nChildren's hospitals in the United States\\nHospitals in Los Angeles\\nHealthcare in Los Angeles\\nHospitals established in 1901\\nEast Hollywood, Los Angeles\\nPediatric trauma centers</td>\n",
       "      <td>The Keck School of Medicine of USC is a medical school in Los Angeles, California. They have teaching hospitals, including children's hospitals, that provide healthcare to people in Los Angeles. The school was established in 1901 and is located in East Hollywood, Los Angeles. They also have a pediatric trauma center.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIDS is a computer virus written in Turbo Pascal 3.01a which overwrites COM files. AIDS is the first virus known to exploit the MS-DOS \"corresponding file\" vulnerability. In MS-DOS, if both  and  exist, then  will always be executed first. Thus, by creating infected  files, AIDS code will always be executed before the intended  code.</td>\n",
       "      <td>This computer virus, called AIDS, is designed to mess up your computer files. It works by taking over important files on your computer, making it hard for your computer to run properly.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The early period of the COVID-19 pandemic necessitated a rapid increase in out-of-office care. To capture the impact from COVID-19 on care for patients with hypertension, a questionnaire was disseminated to community health center clinicians. The extent, types, and causes of care delays and disruptions were assessed along with adaptations and innovations used to address them. Clinician attitudinal changes and perspectives on future hypertension care were also assessed. Of the 65 respondents, most (90.8%) reported their patients with hypertension experienced care delays or disruptions, including lack of follow-up, lack of blood pressure assessment, and missed medication refills or orders. To address care delays and disruptions for patients with hypertension, respondents indicated that their health center increased the use of telehealth or other technology, made home blood pressure devices available to patients, expanded outreach and care coordination, provided medication refills for longer periods of time, and used new care delivery options. The use of self-measured blood pressure monitoring (58.5%) and telehealth (43.1%) was identified as the top adaptations that should be sustained to increase access to and patient engagement with hypertension care; however, barriers to both remain. Policy and system level changes are needed to support value-based care models that include self-measured blood pressure and telehealth.</td>\n",
       "      <td>The COVID-19 pandemic made it difficult for people with high blood pressure to get the care they needed. We wanted to understand how this affected patients and their doctors.  So we asked doctors at community health centers how the pandemic affected their patients with high blood pressure.  Most doctors said their patients had trouble getting care, like missing appointments, not having their blood pressure checked, or not getting their medication refills. To solve these problems, doctors started using new ways to provide care, like telehealth, providing home blood pressure monitors, and making it easier for patients to get their medications. Many doctors believe that using home blood pressure monitoring and telehealth should continue because they can help more people get the care they need for high blood pressure. However, there are still challenges in using these new approaches. We need to make changes to how healthcare is organized to make sure these new ways of providing care work well for everyone.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The poor translation of research findings into routine clinical practice is common in all areas of healthcare. Having a better understanding of how researchers and clinicians experience engagement in and with research, their working relationships and expectations of each other, may be one way to help to facilitate collaborative partnerships and therefore increase successful translation of research into clinical practice. To explore the views of clinical and research staff about their experiences of working together during research projects and identify the facilitators and barriers. We conducted four focus groups with 18 participants - clinicians, researchers and those with a dual clinical-research role, recruited from one mental health Trust and one university. Data was analysed using thematic analysis. Eight themes were identified under the headings of two research questions 1) Barriers and facilitators of either engaging in or with research from the perspective of clinical staff, with themes of understanding the benefits of the research; perceived knowledge and personal qualities of researchers; lack of time and organisational support to be involved in and implement research; and lack of feedback about progress and outcome of research. 2) Barriers and facilitators for engaging with clinicians when conducting research, from the perspective of researchers, with themes of understanding what clinicians need to know and how they need to feel to engage with research; demonstrating an understanding of the clinician's world; navigating through the clinical world; and demands of the researcher role. There was agreement between clinicians and researchers about the barriers and facilitators for engaging clinicians in research. Both groups identified that it was the researcher's responsibility to form and maintain good working relationships. Better support for researchers in their role calls for training in communication skills and bespoke training to understand the local context in which research is taking place.</td>\n",
       "      <td>It's common for medical research findings to not be used in everyday patient care. To improve this, we need to understand how researchers and doctors work together. We want to know how they feel about research, how they interact, and what they expect from each other. We did a study with 18 people – doctors, researchers, and people who work in both roles – from a mental health center and a university. We talked to them in groups and found eight main themes.  Both doctors and researchers agreed that researchers need to build strong relationships with doctors. They also agreed that researchers need more training to understand how to communicate with doctors and to learn about the specific challenges of the places where they are doing research.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cardiothoracic surgery is the field of medicine involved in surgical treatment of organs inside the thoracic cavity — generally treatment of conditions of the heart (heart disease), lungs (lung disease), and other pleural or mediastinal structures.</td>\n",
       "      <td>Cardiothoracic surgery is a branch of medicine that involves operating on organs in the chest, like the heart and lungs. This type of surgery is used to treat various conditions related to these organs.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_random_elements(raw_datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "Before we can feed those texts to our model, we need to preprocess them. This is done by a 🤗 Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that the model requires.\n",
    "\n",
    "To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
    "\n",
    "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
    "- we download the vocabulary used when pretraining this specific checkpoint.\n",
    "\n",
    "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eXNLu_-nIrJI",
    "outputId": "e0879053-849b-4602-bfc4-f4bd576e4a4c"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0VyrvZnd4y5"
   },
   "source": [
    "We can then write the function that will preprocess our samples. We just feed them to the `tokenizer` with the argument `truncation=True`. This will ensure that an input longer that what the model selected can handle will be truncated to the maximum length accepted by the model. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "vc0BSBLIIrJQ"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    inputs = [f'summarization: {original}' for original in examples[original_col]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    labels = tokenizer(text_target=examples[target_col], max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lm8ozrJIrJR"
   },
   "source": [
    "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zS-6iXTkIrJT"
   },
   "source": [
    "To apply this function on all the pairs of sentences in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "d8ea0cd62d974baf97a8b42fa97aaecb",
      "f513b781f17740e1895a3528ad2a1354",
      "c43ab8103fe84bbfb0322b816a68522b",
      "dc252cd58362422591ba3b5e68e9b40a",
      "d09a7418364a489bb66c2ba8f11cbe56",
      "2fe46ae51f9b4a2ba259d59d41d647d8",
      "a2128e92206d4ed0a34766c30051cf33",
      "9f546ffff89e48b9829ab6745a1c0430",
      "e3af4defe97b46bf9956b8e60f40d919",
      "1fb00823e5d44ac7bbcdb6d7dde6ff27",
      "88732ac2fea5451c98e235f8172ce737",
      "12726e56158f4e71b4c520365f9ab077",
      "c3d809ee4fd6495b928fb69a4002c6db",
      "bba103a9c9c544f589b137ccd82c9bca",
      "93f1ec3d4f1b4c8a8015a80128f3c9cc",
      "db33b1be26d049198babab7b3553c05c",
      "f0a8d3f73f474ca18db270f3325563cb",
      "59798a461447466d95d8611ea8d4c8d6",
      "123fb6b28aec4682a36f51736abf1bb9",
      "b1f075b2b2a04221a7eea8a856d49b85",
      "6c77cbe51a5b4b1e871651f333f4008b",
      "804f24fbbb224a60b0d8e84ece6a93e1",
      "fc8a91ee91414568941623e8c47b92cd",
      "73c616b99f4e4f5aacb399b36223627f",
      "fbbd2ac6e10a4f7bbbfb5adef28c436a",
      "a9205ce13e164ce0b964561e01655046",
      "cd60ce2d06944113a9e30799045a8050",
      "343536b24ff84693aee8846808cf85bb",
      "e01c2e8fc1e5452285ba35674616cdfc",
      "a5c21df41b704d6ba6b18ec3ecec7ad9",
      "c07c84533b154ccb917f327e8d1c2cf5",
      "e0cc259efdd5413c8ba5348011bc4678",
      "eec42aa718174275b1a92c76977c2a46"
     ]
    },
    "id": "DDtsaJeVIrJT",
    "outputId": "589d1fbe-868e-4648-faf1-505eece08602"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e348addc294144139e9d883f5dc299ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/63693 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c2c6983c754b7ab2a63ab502812231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad7b9fe62bda4623825660ea3dddbd3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "826e9370ec6f495fa0fea1e43f194932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/63693 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d77da18d039405aa6d1c3f5ef6bd1a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48540b50d44344b4ae40fbf76d3a6634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/321 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True)\n",
    "# tokenized_datasets = tokenized_datasets.filter(lambda example: len(example['labels']) < max_target_length)\n",
    "tokenized_datasets_reduced = tokenized_datasets.filter(lambda example: len(example['labels']) > 5 and len(example['labels']) < 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fbb81c058c04ababa1b84e0fa6898b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/58614 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bfa8272e86f4badb4902249ff279f6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/301 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2a2a616e9048cab4c59458bb463228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/298 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save tokenized_datasets to disk as it is time-consuming to tokenize\n",
    "tokenized_datasets_reduced.save_to_disk(f'{data_dir}/tokenized_datasets_reduced_en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We observe that our reduced dataset with only 256 tokens are sufficient to cover most records as below.**\n",
    "\n",
    "This was done to save memory and improve training speed.\n",
    "* 58.6k / 63.6k (92.0%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    58614.000000\n",
       "mean       132.330757\n",
       "std         55.514934\n",
       "min          6.000000\n",
       "25%         91.000000\n",
       "50%        131.000000\n",
       "75%        173.000000\n",
       "max        255.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.Series([len(label) for label in tokenized_datasets_reduced['train']['labels']])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenized_datasets = load_from_disk(f'{data_dir}/tokenized_datasets_reduced_en') # Load tokenized_datasets from disk\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sZOdRlRIrJd"
   },
   "source": [
    "The last thing to define for our `Seq2SeqTrainer` is how to compute the metrics from the predictions. We need to define a function for this, which will just use the `metric` we loaded earlier, and we have to do a bit of pre-processing to decode the predictions into texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UmvbnJ9JIrJd",
    "outputId": "b97f3b69-8f8e-4de8-9a82-62d1e8342d01"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import evaluate\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.where(predictions != -100, predictions, tokenizer.pad_token_id)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXuFTAzDIrJe"
   },
   "source": [
    "Then we just need to pass all of this along with our datasets to the `Seq2SeqTrainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imY1oC3SIrJf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    model_dir,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    save_strategy=\"steps\",\n",
    "    num_train_epochs=30, # 10 done\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    generation_max_length=max_target_length, \n",
    "    # push_to_hub=True\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdzABDVcIrJg"
   },
   "source": [
    "We can now finetune our model by just calling the `train` method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ADcv2Y4Q3_BQ"
   },
   "source": [
    "## Model evaluation\n",
    "\n",
    "We load the best checkpoint for the model and evaluate its performance against other similar medical text simplification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"t5-base\"\n",
    "model_dir = f\"{model_name.replace('/', '-')}-checkpoints\"\n",
    "\n",
    "# Check if model directory exists and is not empty\n",
    "if os.path.exists(model_dir) and os.listdir(model_dir):\n",
    "    model_checkpoint = os.path.join(model_dir, os.listdir(model_dir)[-1])\n",
    "else:\n",
    "    model_checkpoint = model_name\n",
    "\n",
    "model_t = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AeRtHpVrd4y-",
    "outputId": "b311d2c7-5878-437e-d9b4-b80f8e8b354f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Input: The frequency of skin ulceration makes an important contributor to the morbidity burden in people with sickle cell disease. Many treatment options are available to the healthcare professional, although it is uncertain which treatments have been assessed for effectiveness in people with sickle cell disease. This is an update of a previously published Cochrane Review.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenized_datasets = load_from_disk(f'{data_dir}/tokenized_datasets_reduced_en') # Load tokenized_datasets from disk\n",
    "\n",
    "test_subset = tokenized_datasets['test'].shuffle().select(range(10))\n",
    "test_sources = [r[original_col] for r in test_subset]\n",
    "test_references = [r[target_col] for r in test_subset]\n",
    "print(f\"Sample Input: {test_sources[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:07<00:00,  7.45s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "model_device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_t.to(model_device)\n",
    "\n",
    "batch_size = 16\n",
    "total_samples = len(test_sources)\n",
    "prediction = []\n",
    "\n",
    "# Process inputs in batches\n",
    "for start_idx in tqdm(range(0, total_samples, batch_size)):\n",
    "    end_idx = min(start_idx + batch_size, total_samples)\n",
    "    # tokenized_batch = test_subset[start_idx:end_idx]\n",
    "    batch_sources = test_sources[start_idx:end_idx]\n",
    "\n",
    "    tokenized_batch = tokenizer(batch_sources, max_length=max_input_length, truncation=True, padding=True, return_tensors=\"pt\").to(model_device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model_t.generate(**tokenized_batch, num_beams=8, do_sample=True, min_length=0, max_length=max_target_length)\n",
    "\n",
    "    # Decode the generated output and add to prediction\n",
    "    batch_prediction = tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "    prediction.extend(batch_prediction)\n",
    "# prediction = [nltk.sent_tokenize(o.strip())[0] for o in decoded_output]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "predictions_df = pd.DataFrame(np.array([test_sources, test_references, prediction]).T, columns=['Original sentence', 'Simplified sentence', 'Predicted sentence'])\n",
    "predictions_df.to_csv(f'{results_dir}/predictions-{model_name.replace(\"/\", \"-\")}.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original sentence</th>\n",
       "      <th>Simplified sentence</th>\n",
       "      <th>Predicted sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ovarian cancer is the third most common gynaec...</td>\n",
       "      <td>Ovarian cancer is the third most common type o...</td>\n",
       "      <td>Ovarian cancer is the third most common gyneco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No studies compared liberal versus conservativ...</td>\n",
       "      <td>There were no studies comparing giving lots of...</td>\n",
       "      <td>This review looked at whether giving fluids to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In children with urinary tract infection (UTI)...</td>\n",
       "      <td>Kids with urinary tract infections (UTIs) can ...</td>\n",
       "      <td>This study looked at whether a test called pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We searched the Cochrane Depression, Anxiety a...</td>\n",
       "      <td>We looked for studies that tested different tr...</td>\n",
       "      <td>We searched a database called the Cochrane Dep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Two review authors independently assessed reco...</td>\n",
       "      <td>Researchers looked at studies comparing botuli...</td>\n",
       "      <td>This study looked at whether a medicine called...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>We searched the Cochrane Kidney and Transplant...</td>\n",
       "      <td>We looked for studies relevant to our review i...</td>\n",
       "      <td>We searched a database called the Cochrane Kid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>Ovulatory disturbance is a key diagnostic feat...</td>\n",
       "      <td>Having irregular ovulation is a key sign of po...</td>\n",
       "      <td>Polycystic ovarian syndrome (PCOS) is a seriou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>We identified 18 RCTs examining a range of com...</td>\n",
       "      <td>This study looked at 18 different ways to help...</td>\n",
       "      <td>We looked at 18 studies that tested different ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>Abortion is common worldwide and increasingly ...</td>\n",
       "      <td>Abortion is common around the world.  More and...</td>\n",
       "      <td>Abortion is common around the world, and more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>To assess the efficacy and safety of re-feedin...</td>\n",
       "      <td>This study aims to compare the effects of re-f...</td>\n",
       "      <td>This study aims to compare the effectiveness a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Original sentence  \\\n",
       "0    Ovarian cancer is the third most common gynaec...   \n",
       "1    No studies compared liberal versus conservativ...   \n",
       "2    In children with urinary tract infection (UTI)...   \n",
       "3    We searched the Cochrane Depression, Anxiety a...   \n",
       "4    Two review authors independently assessed reco...   \n",
       "..                                                 ...   \n",
       "293  We searched the Cochrane Kidney and Transplant...   \n",
       "294  Ovulatory disturbance is a key diagnostic feat...   \n",
       "295  We identified 18 RCTs examining a range of com...   \n",
       "296  Abortion is common worldwide and increasingly ...   \n",
       "297  To assess the efficacy and safety of re-feedin...   \n",
       "\n",
       "                                   Simplified sentence  \\\n",
       "0    Ovarian cancer is the third most common type o...   \n",
       "1    There were no studies comparing giving lots of...   \n",
       "2    Kids with urinary tract infections (UTIs) can ...   \n",
       "3    We looked for studies that tested different tr...   \n",
       "4    Researchers looked at studies comparing botuli...   \n",
       "..                                                 ...   \n",
       "293  We looked for studies relevant to our review i...   \n",
       "294  Having irregular ovulation is a key sign of po...   \n",
       "295  This study looked at 18 different ways to help...   \n",
       "296  Abortion is common around the world.  More and...   \n",
       "297  This study aims to compare the effects of re-f...   \n",
       "\n",
       "                                    Predicted sentence  \n",
       "0    Ovarian cancer is the third most common gyneco...  \n",
       "1    This review looked at whether giving fluids to...  \n",
       "2    This study looked at whether a test called pro...  \n",
       "3    We searched a database called the Cochrane Dep...  \n",
       "4    This study looked at whether a medicine called...  \n",
       "..                                                 ...  \n",
       "293  We searched a database called the Cochrane Kid...  \n",
       "294  Polycystic ovarian syndrome (PCOS) is a seriou...  \n",
       "295  We looked at 18 studies that tested different ...  \n",
       "296  Abortion is common around the world, and more ...  \n",
       "297  This study aims to compare the effectiveness a...  \n",
       "\n",
       "[298 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FK index: 10.690000000000001\n",
      "ARI index: 13.05\n",
      "BLEU Score: 0.22555821117555325\n",
      "ROUGE Score: {'rouge1': np.float64(0.5491531509821976), 'rouge2': np.float64(0.29510241772094437), 'rougeL': np.float64(0.4504893575357102), 'rougeLsum': np.float64(0.44968715561786)}\n",
      "METEOR Score: 0.4742659218879215\n",
      "SARI Score: 0.5067694622718653\n",
      "BERTScore: 0.744801664352417\n"
     ]
    }
   ],
   "source": [
    "from metrics import fk, ari, bleu, rouge, meteor, sari, bertscore\n",
    "\n",
    "# Calculate metrics\n",
    "fk_score = fk(prediction)\n",
    "ari_score = ari(prediction)\n",
    "bleu_score = bleu(test_references, prediction)\n",
    "rouge_score = rouge(test_references, prediction)\n",
    "meteor_score = meteor(test_references, prediction)\n",
    "sari_score = sari(test_sources, test_references, prediction)\n",
    "bertscore_score = bertscore(test_references, prediction)\n",
    "\n",
    "print(\"FK index:\", fk_score)\n",
    "print(\"ARI index:\", ari_score)\n",
    "print(\"BLEU Score:\", bleu_score)\n",
    "print(\"ROUGE Score:\", rouge_score)\n",
    "print(\"METEOR Score:\", meteor_score)\n",
    "print(\"SARI Score:\", sari_score)\n",
    "print(\"BERTScore:\", bertscore_score)\n",
    "\n",
    "# NOTE: There can be minor variance in results every time the evaluation is run, a mean of many samples is recommeded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6Bhq8wl2c0f"
   },
   "source": [
    "|                          | Readability |       | Lexical  |        |         |       | Simplification | Semantic  |\n",
    "|--------------------------|:-----------:|:-----:|:--------:|:------:|:-------:|:-----:|:--------------:|:---------:|\n",
    "| Models                   | FK          | ARI   | Rouge1   | Rouge2 | Rouge-L | BLEU  | SARI           | BertScore |\n",
    "| UL-BART (Devraj et al.)  | 11.97       | **13.73** | 38.00    | 14.00  | 36.00   | 39.0  | 40.00          | N/A       |\n",
    "| NapSS (Lu et al.)        | **10.97**       | 14.27 | 48.05    | 19.94  | 44.76   | 12.3  | 40.37          | 25.73     |\n",
    "| T5-base-finetuned (ours) | 11.46       | 14.41 | **54.88**    | **28.85**  | **42.51**   | **51.00**  | **73.70**          | **74.83**     |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End\n",
    "Thank you!!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0bf59dc50c4e44e3afcc0168ffb2402e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1948be0925a143c29840f8ae6b59207e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1ada444d94c94d77ab5e7cb5a994d1d6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_bba35f4707ff40368bc98bdd4a8a5634",
       "style": "IPY_MODEL_f889e86629714babbc51d9bfa67d72a2",
       "value": "vocab.txt: 100%"
      }
     },
     "2acd06021fc44d3fbe5780a9c722c144": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "34fa979beca94ac1859fbd7638d3d407": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_0bf59dc50c4e44e3afcc0168ffb2402e",
       "style": "IPY_MODEL_a680459b96664f2db9c409be3d00ecdd",
       "value": " 228k/228k [00:00&lt;00:00, 475kB/s]"
      }
     },
     "4c0697d3b9fb41a1a669877e3e082bf7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "52ae58d29de046e18f840ab5c84fc0aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_68c9f0e5f406404d9a529cff238b55fd",
       "max": 227845,
       "style": "IPY_MODEL_e0124e4fffee443ea778704dad516bfc",
       "value": 227845
      }
     },
     "53b2ea8fc2bf4b5a9bb1c9d075a57c0d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "57d2c0a2e5014c5f8246aab39ab7a397": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "59cd832710354e9f84e3e4e57fa2c2a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "68c9f0e5f406404d9a529cff238b55fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7338410e8a5d48f9b6b02590fd9628c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "74ccd25360624613bfcde18768d29ac1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "7579b1ca885a43379e35a5ec549cd3b5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "82b2a81705254c7093c41a55c998bc89": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "8bb4f61defa14fa89fc5777993ad39ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_e3d3518f166248fab7e6af234dc9bbcf",
       "style": "IPY_MODEL_57d2c0a2e5014c5f8246aab39ab7a397",
       "value": "pytorch_model.bin: 100%"
      }
     },
     "903da893cdd04054bcb5ca0a113d60c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_d0cfa53decfd47439afaf627d5c0dcf5",
        "IPY_MODEL_c03de71a02b24c87867c1f872f2c281c",
        "IPY_MODEL_9984c07e2a6f4e669d6b79ec7e36ee89"
       ],
       "layout": "IPY_MODEL_74ccd25360624613bfcde18768d29ac1"
      }
     },
     "9674acfe47b8462e92e2fe12c9833fac": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9984c07e2a6f4e669d6b79ec7e36ee89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_82b2a81705254c7093c41a55c998bc89",
       "style": "IPY_MODEL_c3e7982157f84717be8372094ac4b996",
       "value": " 385/385 [00:00&lt;00:00, 63.8kB/s]"
      }
     },
     "9a68c4be60f449d8afa1b7978be52276": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_9c2c3818fdcb4c35865bff5c4d89433d",
       "max": 442221694,
       "style": "IPY_MODEL_7338410e8a5d48f9b6b02590fd9628c1",
       "value": 442221694
      }
     },
     "9c2c3818fdcb4c35865bff5c4d89433d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a680459b96664f2db9c409be3d00ecdd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "bba35f4707ff40368bc98bdd4a8a5634": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c03de71a02b24c87867c1f872f2c281c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_7579b1ca885a43379e35a5ec549cd3b5",
       "max": 385,
       "style": "IPY_MODEL_e63c2fc69ce74a8ca258d76100cc3cab",
       "value": 385
      }
     },
     "c3e7982157f84717be8372094ac4b996": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d0cfa53decfd47439afaf627d5c0dcf5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9674acfe47b8462e92e2fe12c9833fac",
       "style": "IPY_MODEL_4c0697d3b9fb41a1a669877e3e082bf7",
       "value": "config.json: 100%"
      }
     },
     "d5bd8f162fe44d9295475243c1b0e32d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_59cd832710354e9f84e3e4e57fa2c2a7",
       "style": "IPY_MODEL_53b2ea8fc2bf4b5a9bb1c9d075a57c0d",
       "value": " 442M/442M [00:05&lt;00:00, 89.1MB/s]"
      }
     },
     "dd7d4c4158e84e1cb9e1ea3285d99fec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_8bb4f61defa14fa89fc5777993ad39ac",
        "IPY_MODEL_9a68c4be60f449d8afa1b7978be52276",
        "IPY_MODEL_d5bd8f162fe44d9295475243c1b0e32d"
       ],
       "layout": "IPY_MODEL_1948be0925a143c29840f8ae6b59207e"
      }
     },
     "e0124e4fffee443ea778704dad516bfc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "e3d3518f166248fab7e6af234dc9bbcf": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e63c2fc69ce74a8ca258d76100cc3cab": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "f889e86629714babbc51d9bfa67d72a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "fa5933c572fc4744bd59d446dc6e50bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_1ada444d94c94d77ab5e7cb5a994d1d6",
        "IPY_MODEL_52ae58d29de046e18f840ab5c84fc0aa",
        "IPY_MODEL_34fa979beca94ac1859fbd7638d3d407"
       ],
       "layout": "IPY_MODEL_2acd06021fc44d3fbe5780a9c722c144"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
